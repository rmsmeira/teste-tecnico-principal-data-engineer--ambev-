# Case
MVP de plataforma de Data &amp; Analytics para vendas de bebidas. Implementa√ß√£o de pipeline de engenharia de dados com PySpark/Python/SQL, modelagem dimensional (Star Schema) e arquitetura de solu√ß√£o em Cloud (Data Lake/BD). Solu√ß√£o focada em responder KPIs de neg√≥cio e escalabilidade.

# Arquitetura de dados medallion architecture
<img src="https://www.databricks.com/sites/default/files/inline-images/building-data-pipelines-with-delta-lake-120823.png" alt="Preview do projeto" width="900"/>

A arquitetura **Medallion** organiza o fluxo de dados em tr√™s camadas: **Bronze**, **Silver** e **Gold**, garantindo qualidade, consist√™ncia e facilidade de an√°lise.

### üü§ Bronze ‚Äî Dados Brutos

- **Objetivo:** Armazenar os dados em seu formato original, sem transforma√ß√µes.
- **Fontes:** Vendas em pontos de venda, logs de distribui√ß√£o, sensores de estoque.
- **P√∫blico:** Engenheiros de dados.
- **Exemplo:** Arquivos CSV/JSON com todas as transa√ß√µes de vendas di√°rias.

---

### ‚ö™ Silver ‚Äî Dados Limpos e Integrados

- **Objetivo:** Limpar, validar e integrar dados da Bronze.
- **Processos:** Remo√ß√£o de duplicatas, preenchimento de dados faltantes, integra√ß√£o com cat√°logo de produtos e clientes.
- **P√∫blico:** Analistas de dados e cientistas de dados.
- **Exemplo:** Tabela de vendas consolidada por SKU, com informa√ß√µes de cliente e regi√£o.


---

### üü° Gold ‚Äî Dados Enriquecidos para Neg√≥cios

- **Objetivo:** Dados refinados e prontos para an√°lise e tomada de decis√£o.
- **Processos:** Agrega√ß√µes, c√°lculo de KPIs como faturamento, ticket m√©dio e margem de lucro.
- **P√∫blico:** Gestores, executivos e equipe de BI.
- **Exemplo:** Dashboard de vendas regionais e por canal de distribui√ß√£o.

---

### üîÑ Fluxo de Dados

1. Dados **raw** chegam na camada **Bronze**.  
2. Transforma√ß√µes e valida√ß√µes na **Silver**.  
3. Dados agregados e prontos para **relat√≥rios e dashboards** na **Gold**.  

---

### üõ† Tecnologias Utilizadas

![PySpark](https://img.shields.io/badge/-PySpark-EE4C2C?logo=apache-spark&logoColor=fff&style=for-the-badge)
![Python](https://img.shields.io/badge/-Python-3776AB?logo=python&logoColor=fff&style=for-the-badge)
![Delta Lake](https://img.shields.io/badge/-Delta_Lake-1E90FF?logo=databricks&logoColor=fff&style=for-the-badge)
![AWS](https://img.shields.io/badge/-AWS-FF9900?logo=amazon-aws&logoColor=fff&style=for-the-badge)
![Databricks](https://img.shields.io/badge/-Databricks-FC6A2A?logo=databricks&logoColor=fff&style=for-the-badge)
![Streaming Table](https://img.shields.io/badge/-Streaming_Table-00BFFF?logo=apache-spark&logoColor=fff&style=for-the-badge)
![SQL](https://img.shields.io/badge/-SQL-4479A1?logo=postgresql&logoColor=fff&style=for-the-badge)
![Unity Catalog](https://img.shields.io/badge/-Unity_Catalog-8A2BE2?logo=databricks&logoColor=fff&style=for-the-badge)

---

### üìä Benef√≠cios da Arquitetura Medallion

- Qualidade e confiabilidade dos dados.  
- Escalabilidade para grandes volumes de vendas.  
- Agilidade na cria√ß√£o de **dashboards e relat√≥rios estrat√©gicos**.  
- Base para **modelos preditivos** e an√°lises avan√ßadas.

# Pipeline
# Pipeline: de_job_lakehouse_ambev

Este pipeline automatiza a ingest√£o, transforma√ß√£o e organiza√ß√£o de dados no **Lakehouse da Ambev**, seguindo a arquitetura **Bronze ‚Üí Silver ‚Üí Gold**.

---

## Estrutura do Pipeline

**Nome do Job:** `de_job_lakehouse_ambev`

### Trigger
- **pause_status:** `UNPAUSED` ‚Äî o job est√° ativo e pode ser executado automaticamente.
- **file_arrival:** Dispara quando arquivos chegam no diret√≥rio `/Volumes/rodrigo_lakehouse/bronze/brz_vol_ambev/`.

---

## Tasks (Etapas do Pipeline)

### Bronze
- **Objetivo:** Ingest√£o dos dados brutos no Lakehouse.
- **Notebook associado:** `/Workspace/DataTeam/1_bronze/landing_to_bronze`
- **Depend√™ncias:** Nenhuma (primeira etapa do pipeline)

### Silver
- **Objetivo:** Transforma√ß√£o e limpeza dos dados brutos, criando datasets prontos para an√°lises intermedi√°rias.
- **Notebook associado:** `/Workspace/DataTeam/2_silver/bronze_to_silver`
- **Depend√™ncias:** `bronze`
- **Warehouse usado:** `4c3eccbf842bbe66`

### Gold
- **Objetivo:** Transforma√ß√£o final e prepara√ß√£o de dados anal√≠ticos e dashboards.
- **Notebook associado:** `/Workspace/DataTeam/3_gold/silver_to_gold`
- **Depend√™ncias:** `silver`
- **Warehouse usado:** `4c3eccbf842bbe66`

---

## Configura√ß√µes adicionais
- **Queue enabled:** `true` ‚Äî o pipeline usa uma fila de execu√ß√£o para otimiza√ß√£o de performance.
- **Performance target:** `STANDARD` ‚Äî define a configura√ß√£o de performance padr√£o para execu√ß√£o dos notebooks.

<img src="https://drive.google.com/uc?export=view&id=1ncVP3U61ddTjWHcmr2GgpK1WON2CrTIR" alt="Pipeline" width="900"/>


# Modelagem gold

## Star Schema
# Data Warehouse de Vendas - Delta Lake

<img src="https://drive.google.com/uc?export=view&id=1EKVSfJKXBDesr8aj7cCiDnK4lGd2tI0N" alt="Pipeline" width="900"/>

## Descri√ß√£o do Projeto
Este projeto cont√©m um **Data Warehouse dimensional** para an√°lise de vendas, constru√≠do utilizando **Delta Lake**. O modelo inclui uma tabela fato (`fact_sales`) e quatro tabelas dimens√£o (`dim_calendar`, `dim_channels`, `dim_places`, `dim_products`). Ele permite an√°lises de vendas por tempo, canal, local e produto, com suporte a tend√™ncias, sazonalidade e segmenta√ß√µes.

---

## Estrutura do Data Warehouse

### Tabelas Dimens√£o

#### 1. `dim_calendar`
- **skcalendar**: Chave prim√°ria (BIGINT, auto incremento)
- **date**: Data
- **day, month, year**: Componentes da data
- **insertdate**: Timestamp de inser√ß√£o

#### 2. `dim_channels`
- **skchannel**: Chave prim√°ria
- **channel_id**: Identificador do canal
- **trade_chnl_desc, trade_group_desc, trade_type_desc**: Descri√ß√µes do canal
- **start_date, end_date**: Validade do registro
- **current**: Indica se √© registro atual
- **insertdate**: Timestamp de inser√ß√£o

#### 3. `dim_places`
- **skplace**: Chave prim√°ria
- **place_id**: Identificador do local
- **Btlr_Org_LVL_C_Desc**: Descri√ß√£o da organiza√ß√£o/regi√£o
- **start_date, end_date**: Validade do registro
- **current**: Indica se √© registro atual
- **insertdate**: Timestamp de inser√ß√£o

#### 4. `dim_products`
- **skproduct**: Chave prim√°ria
- **product_id**: Identificador do produto
- **ce_brand_flvr, brand_nm**: Marca e sabor
- **pkg_cat, pkg_cat_desc, tsr_pckg_nm**: Categoria e embalagem
- **start_date, end_date**: Validade do registro
- **current**: Indica se √© registro atual
- **insertdate**: Timestamp de inser√ß√£o

---

### Tabela Fato

#### `fact_sales`
- **skcalendar**: FK para `dim_calendar`
- **sales_id**: Identificador da venda
- **skproduct**: FK para `dim_products`
- **skplace**: FK para `dim_places`
- **skchannel**: FK para `dim_channels`
- **volume**: Quantidade vendida
- **insertdate**: Timestamp de inser√ß√£o

---

## Poss√≠veis An√°lises e KPIs

- **Tend√™ncia de vendas**: di√°rio, semanal, mensal, anual.
- **Sazonalidade e picos de demanda**.
- **Performance por canal**: total de vendas por `trade_group_desc`.
- **Performance por regi√£o/local**: total de vendas por `Btlr_Org_LVL_C_Desc`.
- **Performance por produto/marca/categoria**: an√°lise de volume e participa√ß√£o.
- **An√°lises combinadas**: cruzar canal, produto e local para segmenta√ß√£o.
- **KPIs avan√ßados**:
  - Crescimento ano a ano
  - Produtos mais vendidos
  - Identifica√ß√£o de outliers de vendas

